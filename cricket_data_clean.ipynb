{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "dat_path = os.getcwd()[:-4] + 'data/'\n",
    "figures_path = os.getcwd()[:-4] + 'figures/'\n",
    "\n",
    "text_font = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_decor(ax, text_font, major_length, minor_length, linewidth):\n",
    "\n",
    "    ax.spines['top'].set_linewidth(0)\n",
    "    ax.spines['right'].set_linewidth(0)\n",
    "    ax.spines['bottom'].set_linewidth(linewidth)\n",
    "    ax.spines['left'].set_linewidth(linewidth)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=text_font, length=major_length, width=linewidth)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=text_font, length=minor_length, width=linewidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. clean data with min-innings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean():\n",
    "\n",
    "    # find all files with given prefix\n",
    "    files = glob(dat_path + 'ODI_data_new_unmerged*.csv')\n",
    "\n",
    "    odi_data = pd.read_csv(files[0])\n",
    "\n",
    "    odi_data = odi_data.drop_duplicates()\n",
    "    try:\n",
    "        odi_data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "        odi_data.drop(['Unnamed: 0.1'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Splitting the DataFrame into two: one for Team1 and another for Team2\n",
    "    df_T1 = odi_data.filter(regex='_T1|Team1|search_ID|Match_ID|Match_Date|Venue|PoM|Winner', axis=1).copy()\n",
    "    df_T2 = odi_data.filter(regex='_T2|Team2|search_ID|Match_ID|Match_Date|Venue|PoM|Winner', axis=1).copy()\n",
    "\n",
    "    # Renaming columns to remove _T1 and _T2 suffixes\n",
    "    df_T1.columns = df_T1.columns.str.replace('_T1', '')\n",
    "    df_T2.columns = df_T2.columns.str.replace('_T2', '')\n",
    "\n",
    "    df_T1.columns = df_T1.columns.str.replace('Team1', 'Team')\n",
    "    df_T2.columns = df_T2.columns.str.replace('Team2', 'Team')\n",
    "\n",
    "    # Adding columns to indicate batting order\n",
    "    df_T1['Batting_Order'] = 'First'\n",
    "    df_T2['Batting_Order'] = 'Second'\n",
    "\n",
    "    # Concatenate the two DataFrames\n",
    "    odi_final = pd.concat([df_T1, df_T2], axis=0).sort_values(by=['Match_ID', 'Batting_Order', 'bat_pos' ])\n",
    "\n",
    "    # Resetting index\n",
    "    odi_final.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    odi_final.to_csv(dat_path + f'ODI_data_cleaned_merged.csv', index=False)\n",
    "\n",
    "    # return odi_final\n",
    "\n",
    "# data_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. renormalization of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalization(norm_quant):\n",
    "\n",
    "    odi_final = pd.read_csv(dat_path + f'ODI_data_cleaned_merged.csv')\n",
    "    odi_final['Match_Date'] = odi_final['Match_Date'].str.replace(r'(\\d)(st|nd|rd|th)', r'\\1', regex=True)\n",
    "    odi_final['Match_Date'] = pd.to_datetime(odi_final['Match_Date'], format='%d %B, %Y')\n",
    "\n",
    "\n",
    "    global_mean = odi_final[norm_quant].mean()\n",
    "\n",
    "\n",
    "    # Calculate the yearly mean for each year\n",
    "    yearly_means = odi_final.groupby(odi_final['Match_Date'].dt.year)[norm_quant].mean()\n",
    "\n",
    "    # Calculate the renormalization factor for each year\n",
    "    renormalization_factors = global_mean / yearly_means\n",
    "\n",
    "    # Apply the renormalization factor to each score\n",
    "    odi_final['renormalized_bat_run'] = odi_final.apply(lambda x: x['bat_run'] * renormalization_factors.loc[x['Match_Date'].year], axis=1)\n",
    "\n",
    "    odi_final['renormalized_runs'] = odi_final.apply(lambda x: x['Runs'] * renormalization_factors.loc[x['Match_Date'].year], axis=1)\n",
    "\n",
    "    odi_final['renormalized_bowl_runs'] = odi_final.apply(lambda x: x['bowl_runs'] * renormalization_factors.loc[x['Match_Date'].year], axis=1)\n",
    "\n",
    "\n",
    "    odi_final.to_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}.csv', index=False)\n",
    "\n",
    "# renormalization(norm_quant='Runs')\n",
    "# renormalization(0, 'bat_run')\n",
    "# renormalization(0, 'bowl_runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. team match number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_match_no(norm_quant):\n",
    "\n",
    "    odi_final = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}.csv')\n",
    "\n",
    "    odi_final['Match_Date'] = pd.to_datetime(odi_final['Match_Date'])\n",
    "    odi_final = odi_final.sort_values(by='Match_ID')\n",
    "\n",
    "    odi_final = odi_final.drop_duplicates()\n",
    "\n",
    "    odi_final['team_match_num'] = np.nan\n",
    "\n",
    "    odi_final = odi_final.sort_values(by=['Match_ID','Team'])\n",
    "\n",
    "    team_list = np.unique(odi_final['Team'])\n",
    "    match_no = {team: 0 for team in team_list}\n",
    "\n",
    "\n",
    "    for i in tqdm(range(len(odi_final))):\n",
    "\n",
    "        team = odi_final.iloc[i]['Team']\n",
    "\n",
    "        if match_no[team] == 0:\n",
    "            match_no[team] += 1\n",
    "            odi_final.iloc[i, odi_final.columns.get_loc('team_match_num')] = match_no[team]\n",
    "        else:\n",
    "            if (odi_final.iloc[i]['Match_ID'] == odi_final.iloc[i-1]['Match_ID']) and (odi_final.iloc[i]['Team'] == odi_final.iloc[i-1]['Team']):\n",
    "                odi_final.iloc[i, odi_final.columns.get_loc('team_match_num')] = match_no[team]\n",
    "            else:\n",
    "                match_no[team] += 1\n",
    "                odi_final.iloc[i, odi_final.columns.get_loc('team_match_num')] = match_no[team]\n",
    "\n",
    "\n",
    "    odi_final['team_match_num'] = odi_final['team_match_num'].astype(int)\n",
    "\n",
    "    odi_final.to_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num.csv', index=False)\n",
    "\n",
    "# team_match_no(norm_quant='Runs')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. player designations\n",
    "\n",
    "bowlers: players who have bowled in at least 50% of their matches\n",
    "\n",
    "batsmen: players who have batted at position 7 or above in at least 50% of their matches\n",
    "\n",
    "all-rounders: players who are both bowlers and batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_designation(norm_quant):\n",
    "\n",
    "    odi_final = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num.csv')\n",
    "\n",
    "    player_list = np.unique(odi_final['player_name'].astype(str))\n",
    "\n",
    "    odi_final['batsmen'] = np.nan\n",
    "    odi_final['bowler'] = np.nan\n",
    "    odi_final['allrounder'] = np.nan\n",
    "\n",
    "    for player in tqdm(player_list):\n",
    "        player_ind = odi_final[odi_final['player_name'] == player].index\n",
    "        temp_df = odi_final[odi_final['player_name'] == player]\n",
    "\n",
    "        if len(temp_df) == 0:\n",
    "            print(player)\n",
    "            continue\n",
    "\n",
    "        #count number of times bowl_overs is not a number\n",
    "        bowl_overs_nan_count = temp_df['bowl_overs'].isna().sum()\n",
    "        bowl_prop = 1-(bowl_overs_nan_count/len(temp_df))\n",
    "\n",
    "        #count number of times bat_pos is less than or equal to 7\n",
    "        bat_pos_count = len(temp_df[temp_df['bat_pos'] <= 7])\n",
    "        bat_prop = bat_pos_count/len(temp_df)\n",
    "\n",
    "        if bowl_prop >= 0.5:\n",
    "            odi_final.loc[player_ind, 'bowler'] = 1\n",
    "        if bat_prop >= 0.5:\n",
    "            odi_final.loc[player_ind, 'batsmen'] = 1\n",
    "        if (bowl_prop >= 0.5) and (bat_prop >= 0.5):\n",
    "            odi_final.loc[player_ind, 'allrounder'] = 1\n",
    "\n",
    "\n",
    "    # odi_final = odi_final.dropna(subset=['batsmen', 'bowler', 'allrounder'], how='all')\n",
    "\n",
    "\n",
    "    odi_final.to_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv', index=False)\n",
    "        \n",
    "# player_designation(norm_quant='Runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. opposition team wicket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4418/4418 [00:53<00:00, 81.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def opp_team_wicket(norm_quant):\n",
    "\n",
    "    odi_final = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv')\n",
    "\n",
    "    odi_final['opp_wickets'] = np.nan\n",
    "\n",
    "    match_id_list = np.unique(odi_final['Match_ID'])\n",
    "\n",
    "    for match_id in tqdm(match_id_list):\n",
    "        temp_df = odi_final[odi_final['Match_ID'] == match_id]\n",
    "        team_list = np.unique(temp_df['Team'])\n",
    "\n",
    "        if len(team_list) != 2:\n",
    "            continue\n",
    "        \n",
    "        team1_ind = odi_final[(odi_final['Match_ID'] == match_id) & (odi_final['Team'] == team_list[0])].index\n",
    "        team2_ind = odi_final[(odi_final['Match_ID'] == match_id) & (odi_final['Team'] == team_list[1])].index\n",
    "        \n",
    "\n",
    "        team1_df = temp_df[temp_df['Team'] == team_list[0]]\n",
    "        team2_df = temp_df[temp_df['Team'] == team_list[1]]\n",
    "\n",
    "        team1_wickets = team1_df['bowl_wickets'].sum()\n",
    "        team2_wickets = team2_df['bowl_wickets'].sum()\n",
    "\n",
    "        odi_final.loc[team1_ind, 'opp_wickets'] = team1_wickets\n",
    "        odi_final.loc[team2_ind, 'opp_wickets'] = team2_wickets\n",
    "\n",
    "\n",
    "    # odi_final = odi_final.dropna(subset=['opp_wickets'], how='all')\n",
    "\n",
    "    odi_final['bat_pos'] = odi_final['bat_pos'].apply(lambda x: x - 11 if x > 11 else x)\n",
    "\n",
    "    odi_final.to_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv', index=False)\n",
    "\n",
    "\n",
    "# opp_team_wicket(norm_quant='Runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Number of matches with more than 50 overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_than_50_overs(norm_quant):\n",
    "\n",
    "    dat = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv')\n",
    "\n",
    "    ### find number of matches before 1987\n",
    "    dat['Match_Date'] = pd.to_datetime(dat['Match_Date'])\n",
    "    dat = dat.sort_values(by='Match_ID')\n",
    "    dat = dat.drop_duplicates(['Match_ID', 'Overs'])\n",
    "    print(len(dat))\n",
    "    # dat = dat[dat['Match_Date'].dt.year <= 1995]\n",
    "\n",
    "    ### find number of matches where the number of overs is over 50 overs\n",
    "    dat = dat[dat['Overs'] > 50]\n",
    "\n",
    "    print(len(dat))\n",
    "\n",
    "# more_than_50_overs(norm_quant='Runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Number of players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863\n",
      "Number of bowlers: 551\n",
      "Number of batsmen: 580\n",
      "Number of allrounders: 177\n"
     ]
    }
   ],
   "source": [
    "def num_plrs(norm_quant):\n",
    "\n",
    "    df = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv')\n",
    "\n",
    "    print(len(df['player_name'].unique()))\n",
    "\n",
    "    num_bowlers= np.count_nonzero(df.groupby('player_name')['bowler'].count().sort_values(ascending=False).values >=25)\n",
    "    num_batsmen= np.count_nonzero(df.groupby('player_name')['batsmen'].count().sort_values(ascending=False).values >=25)\n",
    "    num_allrounders = np.count_nonzero(df.groupby('player_name')['allrounder'].count().sort_values(ascending=False).values >=25)\n",
    "\n",
    "    print('Number of bowlers:', num_bowlers)\n",
    "    print('Number of batsmen:', num_batsmen)\n",
    "    print('Number of allrounders:', num_allrounders)\n",
    "\n",
    "num_plrs(norm_quant='Runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4418\n",
      "2863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('1971-01-05 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_quant = 'Runs'\n",
    "df = pd.read_csv(dat_path + f'ODI_data_cleaned_merged_renorm_{norm_quant}_with_team_match_num_with_player_designation.csv')\n",
    "\n",
    "\n",
    "print(len(np.unique(df['Match_ID'])))\n",
    "print(len(np.unique(df['player_name'].astype(str))))\n",
    "\n",
    "df['Match_Date'] = pd.to_datetime(df['Match_Date'])\n",
    "\n",
    "min(df['Match_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
